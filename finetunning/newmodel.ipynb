{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW MODEL\n",
    "\n",
    "#ROLLING (absolute) MEAN OF NORMALIZED DATA\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "input_dir = \"mindrove_dataset\"\n",
    "dataval= pd.read_csv(os.path.join(input_dir, \"definitivo_dataset.csv\"))\n",
    "\n",
    "emgval = np.abs(dataval.iloc[:,2:10] * 0.045)\n",
    "data = np.array(emgval)\n",
    "\n",
    "#FIRST: NORMALIZE\n",
    "normalized_data = np.empty_like(data)\n",
    "scalers = []\n",
    "for i in range(data.shape[1]):\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler.fit(data[:, i].reshape(-1, 1))\n",
    "    scalers.append(scaler)\n",
    "for i, scaler in enumerate(scalers):\n",
    "    normalized_data[:, i] = scaler.transform(data[:, i].reshape(-1, 1)).flatten()\n",
    "\n",
    "taskval = dataval.iloc[:,1]\n",
    "newdata = np.zeros(((data.shape[0]),9))\n",
    "newdata[:, 0] = taskval\n",
    "newdata[:, 1:] = normalized_data\n",
    "\n",
    "#SECOND: ROLLING MEAN FOR EACH COLUMN\n",
    "newdata = pd.DataFrame(newdata) #convert to dataframe\n",
    "roll = newdata.rolling(window=10, step=1).mean()\n",
    "roll2 = np.zeros(roll.shape)\n",
    "\n",
    "repetitions = [1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,6,6,6,7,7,7]\n",
    "count=-1\n",
    "#he establecido un treshold para que asigne un task u otro y no haya decimales y\n",
    "#que en total solo sean 7 tasks\n",
    "\n",
    "for i in range(1,(len(roll))):\n",
    "        if not roll.iloc[i,0] == 0 and roll.iloc[i-1,0] == 0:\n",
    "            count += 1\n",
    "        if not roll.iloc[i,0] == 0 and roll.iloc[i,0] < (repetitions[count]/2):\n",
    "            roll2[i,0] = 0\n",
    "        elif not roll.iloc[i,0] == 0 and roll.iloc[i,0] >= (repetitions[count]/2):\n",
    "            roll2[i,0] = repetitions[count]\n",
    "#eliminate first 2 values NaN\n",
    "roll2[9:,1:]= roll.iloc[9:,1:]\n",
    "MAV = roll2[9:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROLLING SSI OF NORMALIZED DATA\n",
    "\n",
    "#FIRST: SQUARED THE NORMALIZED DATA\n",
    "normsquared = np.square(normalized_data)   \n",
    "taskval = dataval.iloc[:,1]\n",
    "newdata = np.zeros(((data.shape[0]),9))\n",
    "newdata[:, 0] = taskval\n",
    "newdata[:, 1:] = normsquared\n",
    "\n",
    "#SECOND: ROLLING SSI FOR EACH COLUMN\n",
    "import pandas as pd\n",
    "newdata = pd.DataFrame(newdata) #convert to dataframe\n",
    "roll = newdata.rolling(window=10, step=1).mean()\n",
    "roll2 = np.zeros(roll.shape)\n",
    "repetitions = [1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,6,6,6,7,7,7]\n",
    "count=-1\n",
    "#he establecido un treshold para que asigne un task u otro y no haya decimales y\n",
    "#que en total solo sean 7 tasks\n",
    "\n",
    "for i in range(1,(len(roll))):\n",
    "        if not roll.iloc[i,0] == 0 and roll.iloc[i-1,0] == 0:\n",
    "            count += 1\n",
    "        if not roll.iloc[i,0] == 0 and roll.iloc[i,0] < (repetitions[count]/2):\n",
    "            roll2[i,0] = 0\n",
    "        elif not roll.iloc[i,0] == 0 and roll.iloc[i,0] >= (repetitions[count]/2):\n",
    "            roll2[i,0] = repetitions[count]\n",
    "#eliminate first 9 values NaN           \n",
    "roll2[9:,1:]= roll.iloc[9:,1:]\n",
    "SSI = roll2[9:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#JOIN\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m datasvm \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat([MAV, SSI[:,\u001b[39m1\u001b[39;49m:]], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\sofia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sofia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobjs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m         objs,\n\u001b[0;32m    370\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    371\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[0;32m    372\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[0;32m    373\u001b[0m         keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[0;32m    374\u001b[0m         levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[0;32m    375\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    376\u001b[0m         verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[0;32m    377\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    378\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    379\u001b[0m     )\n\u001b[0;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\sofia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:458\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[0;32m    454\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    455\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot concatenate object of type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(obj)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39monly Series and DataFrame objs are valid\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m         )\n\u001b[1;32m--> 458\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    460\u001b[0m     ndims\u001b[39m.\u001b[39madd(obj\u001b[39m.\u001b[39mndim)\n\u001b[0;32m    462\u001b[0m \u001b[39m# get the sample\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[39m# want the highest ndim that we have, and must be non-empty\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[39m# unless all objs are empty\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "#JOIN\n",
    "datasvm = pd.concat([MAV, SSI[:,1:]], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
